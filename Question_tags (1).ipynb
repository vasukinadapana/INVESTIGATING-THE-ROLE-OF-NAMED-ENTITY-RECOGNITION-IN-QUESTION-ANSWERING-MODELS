{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jylX-IlI2MB",
        "outputId": "fcf5005a-7e47-4e5f-ec5e-25b72b906fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Identify-Question-Type'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Total 26 (delta 0), reused 0 (delta 0), pack-reused 26\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rishikksh20/Identify-Question-Type.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOhpPG2PJBiP",
        "outputId": "9442a792-7fc6-4a94-b408-f4569d998628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==1.0.0\n",
            "  Downloading Keras-1.0.0.tar.gz (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting theano\n",
            "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==1.0.0) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.0.0) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.0.0) (1.4.1)\n",
            "Building wheels for collected packages: keras, theano\n",
            "  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras: filename=Keras-1.0.0-py3-none-any.whl size=130498 sha256=3ea609ff939be5ccb0c0d8020efe531eb5a48839d8859cf9e4d67729535e9db0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/2c/5d/05f97a2a95bab04657f01b979b1c8cffead1da5d8a5e6e7b62\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668111 sha256=46e9ea30136edd4724c60b3071d296d922a73018a6b2d8d0c9a597e30f524a77\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
            "Successfully built keras theano\n",
            "Installing collected packages: theano, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 1.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-1.0.0 theano-1.0.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKcnHkCOJQCJ",
        "outputId": "2e3a1336-c79e-413d-ae66-c1ddc04ff68f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/Identify-Question-Type/label.txt\",sep=\",,,\",header=None ,names=['question','type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u_RQftLoQpYY",
        "outputId": "125d6235-b61c-4f35-e4ac-993254388265"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-30644b6b-9eca-4f67-b138-318ccfeaaf9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how did serfdom develop in and then leave russ...</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what films featured the character popeye doyle ?</td>\n",
              "      <td>what</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how can i find a list of celebrities ' real na...</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what fowl grabs the spotlight after the chines...</td>\n",
              "      <td>what</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what is the full form of .com ?</td>\n",
              "      <td>what</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30644b6b-9eca-4f67-b138-318ccfeaaf9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30644b6b-9eca-4f67-b138-318ccfeaaf9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30644b6b-9eca-4f67-b138-318ccfeaaf9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            question      type\n",
              "0  how did serfdom develop in and then leave russ...   unknown\n",
              "1  what films featured the character popeye doyle ?       what\n",
              "2  how can i find a list of celebrities ' real na...   unknown\n",
              "3  what fowl grabs the spotlight after the chines...      what\n",
              "4                   what is the full form of .com ?       what"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_frdR01Qs9T",
        "outputId": "8aff2b5c-58ee-4d9f-f684-3713c20e1cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1483, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa8vUHsyQy8h"
      },
      "outputs": [],
      "source": [
        "df['type']=df['type'].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jACwMV9Q16t",
        "outputId": "913b6823-10a0-4fad-d9de-857f395c60a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['unknown', 'what', 'when', 'who', 'affirmation'], dtype=object)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oztoRw4ORBwL",
        "outputId": "0f9fc5c5-98c8-47e3-83f1-c71c754c11e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['how did serfdom develop in and then leave russia ? ',\n",
              "       'what films featured the character popeye doyle ? ',\n",
              "       \"how can i find a list of celebrities ' real names ? \", ...,\n",
              "       'does this hose have one ? ', 'can i get it in india ? ',\n",
              "       'would this work on a 2008 ford edge with a naked roof ? '],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['question'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0m-Hzj9REJq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "df['question'] = df['question'].apply(lambda x: x.lower())\n",
        "df['question'] = df['question'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaxHM6xzRKsM"
      },
      "outputs": [],
      "source": [
        "VALIDATION_SPLIT=0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hTb1FXdRR9c"
      },
      "outputs": [],
      "source": [
        "from collections import Counter, defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle as pkl\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# organize imports\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iW54ozGRVYB"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmJVOh3zRY23"
      },
      "outputs": [],
      "source": [
        "class StemTokenizer(object):\n",
        "    def __init__(self):\n",
        "        self.ignore_set = {'footnote', 'nietzsche', 'plato', 'mr.'}\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        words = []\n",
        "        for word in word_tokenize(doc):\n",
        "            word = word.lower()\n",
        "            w = wn.morphy(word)\n",
        "            if w and len(w) > 1 and w not in self.ignore_set:\n",
        "                words.append(w)\n",
        "        return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipTUDPaORcjF"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer('english').stem\n",
        "def stem_tokenize(text):\n",
        "    return [stemmer(i) for i in word_tokenize(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvm4sBSARgL9",
        "outputId": "57954e6d-65e8-4900-c5cc-bd70cbe4bf05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "vectorizer = CountVectorizer(analyzer='word',lowercase=True,tokenizer=stem_tokenize)\n",
        "X_train = vectorizer.fit_transform(df.question.values)\n",
        "with open('vectorizer.pk', 'wb') as fin:\n",
        "    pkl.dump(vectorizer, fin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrtGvkuERjDl"
      },
      "outputs": [],
      "source": [
        "labels = df['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEy0KyrXRwPS"
      },
      "outputs": [],
      "source": [
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "X_train = X_train[indices]\n",
        "labels = labels[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * X_train.shape[0])\n",
        "\n",
        "x_train = X_train[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = X_train[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsOzn5tnR2He",
        "outputId": "457da92a-18a1-4a1d-991c-dbb332831604"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHFEqBfZR_I5",
        "outputId": "981d1958-64f6-45e1-fa0e-5b1fab30bc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " affirmation       0.86      1.00      0.92        18\n",
            "     unknown       0.81      0.95      0.87        40\n",
            "        what       0.98      0.85      0.91       136\n",
            "        when       0.52      0.92      0.67        13\n",
            "         who       1.00      0.98      0.99        89\n",
            "\n",
            "    accuracy                           0.92       296\n",
            "   macro avg       0.83      0.94      0.87       296\n",
            "weighted avg       0.94      0.92      0.92       296\n",
            "\n",
            "Accuracy : 0.9155405405405406\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model of test data\n",
        "preds = clf.predict(x_val)\n",
        "print(classification_report(preds,y_val))\n",
        "print(\"Accuracy :\",clf.score(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEO3mbOwSC4n",
        "outputId": "7614e4fe-1de5-4b4d-e86d-3da61c3f765d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['what'], dtype='<U11')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example=vectorizer.transform([\"What time does the train leave\"])\n",
        "clf.predict(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uDl9OEuSLf9"
      },
      "outputs": [],
      "source": [
        "tf_vectorizer = TfidfVectorizer(analyzer='word',lowercase=True,tokenizer=stem_tokenize)\n",
        "X_train = tf_vectorizer.fit_transform(df.question.values)\n",
        "with open('tf_vectorizer.pk', 'wb') as fin:\n",
        "    pkl.dump(tf_vectorizer, fin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orNZ3I3pSSfT"
      },
      "outputs": [],
      "source": [
        "labels = df['type']\n",
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "X_train = X_train[indices]\n",
        "labels = labels[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * X_train.shape[0])\n",
        "\n",
        "x_train = X_train[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = X_train[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDGzHrSpSYo4",
        "outputId": "5c41790b-2cbe-4bbd-f93c-9e0581cb6303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XwXZBQcShKk",
        "outputId": "5c140a38-1e1f-4473-9b43-8e8d87f458ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['what'], dtype='<U11')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example=tf_vectorizer.transform([\"What time does the train leave\"])\n",
        "clf.predict(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nc1KJPVUPjoH",
        "outputId": "df38a216-4f6c-4ec0-abed-f456a1a2bb07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 1.0.0\n",
            "    Uninstalling Keras-1.0.0:\n",
            "      Successfully uninstalled Keras-1.0.0\n",
            "Successfully installed keras-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import keras\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JpylgrDPpCT"
      },
      "outputs": [],
      "source": [
        "MAX_NB_WORDS = 20000\n",
        "MAX_SEQUENCE_LENGTH=30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf6lie0xPsg7"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu_cmLEyPvh0"
      },
      "outputs": [],
      "source": [
        "data=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVXcFF4-PyFC",
        "outputId": "e2cb165a-8c67-45de-8efb-4f5092e999da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what           609\n",
            "who            402\n",
            "unknown        272\n",
            "affirmation    104\n",
            "when            96\n",
            "Name: type, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data['type'].value_counts())\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ')\n",
        "tokenizer.fit_on_texts(data['question'].values)\n",
        "X = tokenizer.texts_to_sequences(data['question'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oHfM7kBP2X9",
        "outputId": "6c0bfe53-c24b-47a3-d76b-561d5e296d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3685 unique tokens.\n",
            "Shape of data tensor: (1483, 30)\n",
            "Shape of label tensor: (1483, 5)\n"
          ]
        }
      ],
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "Y = data['type']\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(Y)\n",
        "Y=le.transform(Y) \n",
        "labels = to_categorical(np.asarray(Y))\n",
        "print('Shape of data tensor:', X.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "\n",
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "X = X[indices]\n",
        "labels = labels[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * X.shape[0])\n",
        "\n",
        "x_train = X[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = X[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEBY2jg8QGO9",
        "outputId": "70e614c1-a9dc-4de9-d79a-fca6bd8a9047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-14 09:28:05--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2022-04-14 09:28:05--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2022-04-14 09:28:05--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  5.18MB/s    in 5m 53s  \n",
            "\n",
            "2022-04-14 09:33:59 (5.07 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpfVzqu-S9Mz",
        "outputId": "2a319501-ee8c-43ef-b8ba-bcc435ef7ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/glove.42B.300d.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz5UBIEVP7U4",
        "outputId": "434a9c68-2231-49a6-8825-853c8118819a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1917494 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/glove.42B.300d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmIqV7qQQAtN"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM=300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2YdrzmfU7JH"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjCtQcVQU-J5",
        "outputId": "75cab00d-fa32-4b7d-a869-d78c3512003c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v1.py:278: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfEg2ANIgllB"
      },
      "outputs": [],
      "source": [
        "?LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBA9vQrnVCTU",
        "outputId": "1c2b159d-3a58-4566-bd89-c8ebb8892347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 30, 300)           1105800   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               389648    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 196)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 985       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,496,433\n",
            "Trainable params: 390,633\n",
            "Non-trainable params: 1,105,800\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 300\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(lstm_out, recurrent_dropout=0.25))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZMf2n8CVF8P",
        "outputId": "6fe8aa03-9bb0-4511-b237-ff800b5427f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 1187 samples, validate on 296 samples\n",
            "Epoch 1/20\n",
            "1187/1187 [==============================] - ETA: 0s - loss: 1.3569 - acc: 0.4305"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1187/1187 [==============================] - 6s 5ms/sample - loss: 1.3569 - acc: 0.4305 - val_loss: 1.2133 - val_acc: 0.5642\n",
            "Epoch 2/20\n",
            "1187/1187 [==============================] - 2s 1ms/sample - loss: 0.9842 - acc: 0.6310 - val_loss: 0.8734 - val_acc: 0.6791\n",
            "Epoch 3/20\n",
            "1187/1187 [==============================] - 2s 1ms/sample - loss: 0.5828 - acc: 0.8029 - val_loss: 0.5271 - val_acc: 0.8378\n",
            "Epoch 4/20\n",
            "1187/1187 [==============================] - 1s 1ms/sample - loss: 0.3756 - acc: 0.8821 - val_loss: 0.4120 - val_acc: 0.8919\n",
            "Epoch 5/20\n",
            "1187/1187 [==============================] - 2s 1ms/sample - loss: 0.2550 - acc: 0.9360 - val_loss: 0.2874 - val_acc: 0.9324\n",
            "Epoch 6/20\n",
            "1187/1187 [==============================] - 1s 1ms/sample - loss: 0.1636 - acc: 0.9579 - val_loss: 0.2769 - val_acc: 0.9392\n",
            "Epoch 7/20\n",
            "1187/1187 [==============================] - 1s 1ms/sample - loss: 0.1166 - acc: 0.9739 - val_loss: 0.2506 - val_acc: 0.9358\n",
            "Epoch 8/20\n",
            "1187/1187 [==============================] - 1s 739us/sample - loss: 0.0839 - acc: 0.9823 - val_loss: 0.2336 - val_acc: 0.9561\n",
            "Epoch 10/20\n",
            "1187/1187 [==============================] - 1s 723us/sample - loss: 0.0782 - acc: 0.9823 - val_loss: 0.2289 - val_acc: 0.9527\n",
            "Epoch 11/20\n",
            "1187/1187 [==============================] - 1s 719us/sample - loss: 0.0642 - acc: 0.9882 - val_loss: 0.2112 - val_acc: 0.9561\n",
            "Epoch 12/20\n",
            "1187/1187 [==============================] - 1s 725us/sample - loss: 0.0517 - acc: 0.9899 - val_loss: 0.2200 - val_acc: 0.9628\n",
            "Epoch 13/20\n",
            "1187/1187 [==============================] - 1s 732us/sample - loss: 0.0482 - acc: 0.9899 - val_loss: 0.2104 - val_acc: 0.9595\n",
            "Epoch 14/20\n",
            "1187/1187 [==============================] - 1s 729us/sample - loss: 0.0447 - acc: 0.9882 - val_loss: 0.2436 - val_acc: 0.9527\n",
            "Epoch 15/20\n",
            "1187/1187 [==============================] - 1s 738us/sample - loss: 0.0557 - acc: 0.9857 - val_loss: 0.2167 - val_acc: 0.9493\n",
            "Epoch 16/20\n",
            "1187/1187 [==============================] - 1s 725us/sample - loss: 0.0497 - acc: 0.9865 - val_loss: 0.2415 - val_acc: 0.9527\n",
            "Epoch 17/20\n",
            "1187/1187 [==============================] - 1s 742us/sample - loss: 0.0395 - acc: 0.9916 - val_loss: 0.2584 - val_acc: 0.9426\n",
            "Epoch 18/20\n",
            "1187/1187 [==============================] - 1s 735us/sample - loss: 0.0330 - acc: 0.9933 - val_loss: 0.2311 - val_acc: 0.9493\n",
            "Epoch 19/20\n",
            "1187/1187 [==============================] - 1s 736us/sample - loss: 0.0272 - acc: 0.9933 - val_loss: 0.2495 - val_acc: 0.9459\n",
            "Epoch 20/20\n",
            "1187/1187 [==============================] - 1s 748us/sample - loss: 0.0216 - acc: 0.9958 - val_loss: 0.2563 - val_acc: 0.9459\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4460331350>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_data=(x_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAmshTlGj753"
      },
      "outputs": [],
      "source": [
        "example = tokenizer.texts_to_sequences([\"When time does the train leave\"])\n",
        "example = pad_sequences(example, maxlen=MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0ozLMRYkKfj",
        "outputId": "82e9267e-9a4d-4fd2-eed6-9a5de33f2cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['when'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "print(np.argmax(model.predict(example)))\n",
        "le.inverse_transform(np.array([np.argmax(model.predict(example))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q3nymTckNlp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Question_tags.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}